# enfr

## processed
- europarl
- Tatoeba 
- JRC-Acquis
- newstest (dev 2015)

## to clean
- common crawl
- undoc
- giga

### to download
- GlobalVoices
- TedTalk
- EAC
- Multi30k
- [OPUS](http://opus.nlpl.eu/)

## data clean
```bash
# TBD
```

## normalization
some uniform transformation on the source sequences to identify and protect some specific sequences (for instance url), normalize characters (for instance all types of quotes, unicode variants) or even to normalize some variants (like dates) into unique representation simpler for the translation process
```bash
# TBD
```

## preprocessing by bpe

### tokenization before bpe
```bash
onmt-tokenize-text --tokenizer OpenNMTTokenizer --tokenizer_config enfr/config/tokenization/no_bpe.yml < input > output
```

### bpe
segment text into subword units by python package
```bash
subword-nmt learn-joint-bpe-and-vocab --input {train_file}.L1 {train_file}.L2 -s {num_operations} -o {codes_file} --write-vocabulary {vocab_file}.L1 {vocab_file}.L2
```
re-apply with vocab filter
```bash
subword-nmt apply-bpe -c {codes_file} --vocabulary {vocab_file}.L1 --vocabulary-threshold 50 < {train_file}.L1 > {train_file}.BPE.L1
```

### build vocabulary
build vocab with bpe tok
```bash
onmt-build-vocab --tokenizer OpenNMTTokenizer --tokenizer_config token_config --size 50000 --save_vocab vocab_path train_path
```

## preprocessing by spm

### spm train
```bash
spm_train --input=all_text --model_prefix=model_name --vocab_size=num --character_coverage=1
```

### spm encode
```bash
spm_encode --model=model_path < file > file.sp
```

### clean vocab from spm
we keep the first field of the vocab file generated by SentencePiece and remove the first line <unk>
```bash
cut -f 1 spm.vocab | tail -n +2 > spm.vocab.tmp
```
we add the <blank> word in first position, needed for OpenNMT-TF
```bash
sed -i '1i<blank>' spm.vocab.tmp
```
last tweak we replace the empty line supposed to be the "tab" character (removed by the cut above)
```bash
perl -pe '$/=""; s/\n\n/\n\t\n/;' spm.vocab.tmp > spm.vocab
```
```bash
rm spm.vocab.tmp
```


## train
```bash
CUDA_VISIBLE_DEVICES=0,1,2,3 onmt-main train_and_eval --model model_path --config train_config --num_gpus 4
```
or model exist
```bash
CUDA_VISIBLE_DEVICES=0,1,2,3 onmt-main train_and_eval --model_type Transformer --config train_config --num_gpus 4
```

# TO BE MODIFIED

## release
```bash
th tools/release_model.lua -gpuid 1 -model /path/model
```

## translate
```bash
th translate.lua -replace_unk -tok_src_mode aggressive -tok_tgt_mode aggressive -tok_src_case_feature -tok_tgt_case_feature -tok_src_segment_numbers -tok_tgt_segment_numbers -tok_src_joiner_annotate -tok_tgt_joiner_annotate -detokenize_output -beam_size 10 -tok_src_bpe_model /src/bpe -tok_tgt_bpe_model /tgt/bpe -model /path/model -src /path/src -output /path/output
```

## server
```bash
th tools/rest_translation_server.lua -host 127.0.0.1 -port 9201 -mode aggressive -segment_numbers -joiner_annotate -replace_unk -beam_size 10 -case_feature -bpe_model /path/bpe -model /path/model 
```

## multi server
```bash
th tools/rest_multi_models.lua -port 9201 -model_config /path/yml
```
config file example
```yaml
-
  model: '/path/model'
  mode: 'aggressive'
  case_feature: true
  segment_numbers: true
  bpe_model: '/model/bpe'
  joiner_annotate: true
  replace_unk: true
  beam_size: 10
```


